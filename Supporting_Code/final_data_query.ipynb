{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce23c492-4913-40fc-9dcc-49df2ef90f1a",
   "metadata": {},
   "source": [
    "# Final Data Combining and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55560693-3e97-4606-91f2-43c62e1ba94a",
   "metadata": {},
   "source": [
    "In this notebook, the data is queried, combined, and cleaned. Additionally, the resulting DataFrame is assessed for missing data.\n",
    "\n",
    "### Final data:\n",
    "- Temporal resolution: hourly\n",
    "- Spatial resolution: California Independent System Operator (CAISO) system-wide\n",
    ">- All data was available on CAISO-wide resolution except for locational marginal price (LMP) data, representing electricity price at specific grid locations\n",
    ">- LMP data was aggregated to the system-wide level as a load-weighted sum of default load aggregation point (DLAP) LMPs; DLAPs are nodes where regional demand is aggregated and priced\n",
    ">- All primary CAISO DLAPs are included in this analysis: PGE, SCE, SDGE, and VEA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6fba7-7ec3-4522-aa00-ec902f982e8d",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "\n",
    "All data was pulled from CAISO sources, described below:\n",
    "\n",
    "- Production, curtailment, and imports/exports: https://www.caiso.com/library/production-curtailments-data\n",
    "- Load: https://www.caiso.com/library/historical-ems-hourly-load\n",
    ">- Pre-cleaning performed prior to import into Jupyter notebook: Removed 'CAISO Public' cell from the bottom of some of the CSVs (not present on every CSV) to prevent issues when reading into a DataFrame\n",
    "- LMP and LMP congestion: https://oasis.caiso.com/mrioasis/logon.do\n",
    ">- Pre-cleaning performed prior to import into Jupyter notebook: see 'LMP_data_query.ipynb' for data query and modification\n",
    "- Battery storage: https://www.caiso.com/library/daily-energy-storage-reports\n",
    ">- Pre-cleaning performed prior to import into Jupyter notebook: CAISO releases battery storage reports quarterly in .XLS format ('storage-report-2023q1', etc.). The data from the four 2023 and four 2024 reports' 'market_output' tab was copied and pasted into a single Excel file. Then Excel filtering was used to only retain data for 'RES_TYPE' = 'LESR' (limited-energy storage resources in CAISO) and 'MARKET' = 'RTD' (the real-time market). The 'TYPE' column was used to filter for 'EN' which represents charging deltas in an interval and 'SOC' which represents the state-of-charge at the end of an interval. The data for 'SOC' and 'EN' was separated into two separate Excel files, 'battery_soc' and 'battery_en'. Finally, the battery data was aggregated hourly. The original data includes columns for hour (1-24) and interval (1-12, every 5 minutes). For 'SOC', the hourly value was calculated as the average of the values for the 12 intervals. For 'EN', the hourly value was taken as the 12th interval's value from each hour. Once the hourly value was selected, the interval column was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f69ad9a-467a-4623-b34f-d35baa06ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries\n",
    "import pandas as pd\n",
    "import gridstatus\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import median_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e9b7fe-e6f9-4e30-841a-0902dc9b221e",
   "metadata": {},
   "source": [
    "Importing and cleaning production, curtailment, export, load, battery storage, and LMP data from 2023 & 2024 to compile a single tidy DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa5435e-fd7d-4c17-b1ee-663a959599ab",
   "metadata": {},
   "source": [
    "## Production, Curtailment, and Import/Export Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b544923b",
   "metadata": {},
   "source": [
    "First, we import the Excel files that include total generation and generation by source from the 'Production' tab of the production and curtailments Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0840de3b-cdc4-4361-81dd-b30640e81308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate timestamps for production data in 2023: 0\n",
      "Duplicate timestamps for production data in 2024: 0\n"
     ]
    }
   ],
   "source": [
    "## Import, format, and aggregate production and import/export data\n",
    "prod_df = pd.DataFrame()\n",
    "\n",
    "## Compile data from 2023 & 2024\n",
    "for year in ['2023', '2024']:\n",
    "    prod = pd.DataFrame()\n",
    "    \n",
    "    # Production data\n",
    "    prod = pd.read_excel(fr\"Production_Curtailment/productionandcurtailmentsdata_{year}.xlsx\", sheet_name='Production')\n",
    "    prod['timestamp'] = pd.to_datetime(prod['Date']) # 'Date' column already includes time\n",
    "    prod['timestamp'] = prod['timestamp'].dt.tz_localize('US/Pacific', ambiguous='infer', nonexistent='shift_forward').dt.tz_convert('UTC') # Handle daylight savings and convert to UTC\n",
    "    print(f'Duplicate timestamps for production data in {year}:', prod['timestamp'].duplicated().sum()) # Check for duplicated timestamps after converting to UTC\n",
    "    \n",
    "    prod.drop(columns=['Date', 'Hour', 'Interval'], inplace=True) # Drop columns that are problematic for aggregation\n",
    "    prod = prod.set_index('timestamp').resample('h').sum().reset_index() # Aggregate total production by hour\n",
    "    prod['percent_wind_gen'] = prod['Wind'] / prod['Generation'] # New column for % wind generation\n",
    "    prod['percent_solar_gen'] = prod['Solar'] / prod['Generation'] # New column for % solar generation\n",
    "\n",
    "    # Concatenate to existing data\n",
    "    prod_df = pd.concat([prod_df, prod], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76652546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hours in range:  17544\n",
      "Total hours in production data:  17544\n"
     ]
    }
   ],
   "source": [
    "# Check legnth of production data compared to total number of hours in the range\n",
    "print('Total hours in range: ', 365 * 24 + 366 * 24) # 2024 is a leap year\n",
    "print('Total hours in production data: ', len(prod_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9445de",
   "metadata": {},
   "source": [
    "Next, we import the Excel files that include curtailment by type (wind or solar) from the 'Curtailments' tab of the production and curtailments Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad50087-b69e-416f-801b-1c2fab044192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate timestamps for curtailment data in 2023: 0\n",
      "Duplicate timestamps for curtailment data in 2024: 0\n"
     ]
    }
   ],
   "source": [
    "## Import, format, and aggregate curtailment data\n",
    "curt_df = pd.DataFrame()\n",
    "\n",
    "## Compile data from 2023 & 2024\n",
    "for year in ['2023', '2024']:\n",
    "    curt = pd.DataFrame()\n",
    "\n",
    "    # Curtailment data\n",
    "    curt = pd.read_excel(fr\"Production_Curtailment/productionandcurtailmentsdata_{year}.xlsx\", sheet_name='Curtailments')\n",
    "    curt = curt.groupby(['Date', 'Hour', 'Interval']).agg({'Wind Curtailment': 'sum', 'Solar Curtailment': 'sum'}).reset_index() # Aggregate across reasons 'System' and 'Local' before adding timestamps\n",
    "    curt['timestamp'] = pd.to_datetime(curt['Date']) + pd.to_timedelta(curt['Hour'] - 1, unit='h') # Create timestamp 'Day' and'Hour' columns\n",
    "    \n",
    "    curt['timestamp'] = curt['timestamp'].dt.tz_localize('US/Pacific', ambiguous='NaT', nonexistent='shift_forward') # Localize to US/Pacific time - cannot infer because timestamps are sparse\n",
    "    curt['timestamp'] = curt['timestamp'].dt.tz_convert('UTC') # Convert to UTC\n",
    "\n",
    "    curt.drop(columns=['Date', 'Hour', 'Interval'], inplace=True) # Drop columns that are problematic for aggregation\n",
    "    curt = curt.groupby(curt['timestamp']).sum().reset_index()\n",
    "    print(f'Duplicate timestamps for curtailment data in {year}:', curt['timestamp'].duplicated().sum()) # Check for duplicated timestamps\n",
    "\n",
    "    curt_df = pd.concat([curt_df, curt], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54affdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hours in range:  17544\n",
      "Total hours in curtailment data:  9298\n"
     ]
    }
   ],
   "source": [
    "# Check legnth of curtailment data compared to total number of hours in the range\n",
    "print('Total hours in range: ', 365 * 24 + 366 * 24) # 2024 is a leap year\n",
    "print('Total hours in curtailment data: ', len(curt_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8470a8",
   "metadata": {},
   "source": [
    "The curtailment DataFrame does not include values for every hour in the timerange because curtailment does not not occur every interval. This is stated in the 'read_me' tab of the source Excel files.\n",
    "\n",
    "Now, we can merge our production and curtailment data using our timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e222225-e074-4e3f-ac62-2942a9fc40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge production and curtailment data using production timestamps\n",
    "prod_and_curt = pd.merge(prod_df, curt_df, left_on=['timestamp'], right_on=['timestamp'], how='left') # Merge on timestamp\n",
    "\n",
    "# Filter only for important columns\n",
    "prod_and_curt = prod_and_curt[['timestamp', 'percent_wind_gen', 'percent_solar_gen', 'Wind Curtailment', 'Solar Curtailment', 'Imports']]\n",
    "prod_and_curt['total_curtailment'] = prod_and_curt['Wind Curtailment'] + prod_and_curt['Solar Curtailment'] # New column for total curtailment\n",
    "prod_and_curt['exports'] = -1 * prod_and_curt['Imports'] # Change sign to represent exports instead of imports\n",
    "\n",
    "# Fill in intervals with no curtailment with 0\n",
    "prod_and_curt['total_curtailment'] = prod_and_curt['total_curtailment'].fillna(0) # Not every hour has any curtailment, so fill in NA with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb70d729-3dec-483b-a432-1fe75e7d21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename and drop columns\n",
    "prod_and_curt.drop(['Wind Curtailment', 'Solar Curtailment', 'Imports'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f803fe-32dc-4f35-b8d3-10ce4ef39828",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3bf3e",
   "metadata": {},
   "source": [
    "Next, we will load our demand data. Demand data was released in a singular Excel report for 2023, but individual monthly Excel reports were released for 2024. We will loop through that folder to pull all of the data for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0ff550-0c73-4e26-821e-5c902d62648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import, format, and aggregate load data from 2023 and 2024\n",
    "\n",
    "## 2024 load data is separated by month -> pull each file from folder and concatenate\n",
    "folder = r\"Load/2024\"\n",
    "all_files = [f for f in os.listdir(folder) if f.endswith('.xlsx')]\n",
    "\n",
    "load_2024 = pd.DataFrame()\n",
    "\n",
    "for file in all_files: # Each file in folder\n",
    "    path = os.path.join(folder, file)\n",
    "\n",
    "    load = pd.read_excel(path) # Read file\n",
    "    load_2024 = pd.concat([load_2024, load], ignore_index=True) # Concatenate to existing\n",
    "    load_2024 = load_2024.sort_values(['Date', 'HR']).reset_index(drop=True) # Sort by time\n",
    "\n",
    "## Pull 2023 data - all in one file\n",
    "load_df = pd.read_excel(r\"Load/historicalemshourlyloadfor2023.xlsx\")\n",
    "\n",
    "## Combine into one DataFrame\n",
    "load_df = pd.concat([load_df, load_2024], ignore_index=True)\n",
    "load_df = load_df.sort_values(['Date', 'HR']).reset_index(drop=True) # Sort by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2e6d2f-bc8f-4f11-a39a-830a5f30d9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate timestamps for load data: 0\n"
     ]
    }
   ],
   "source": [
    "## Convert day/time columns to timestamps in load data\n",
    "load_df['timestamp'] = pd.to_datetime(load_df['Date']) + pd.to_timedelta(load_df['HR'], unit='h') # Create timestamp column from 'Date' and 'Hour'; Hour 1 is actually 1:00 - 1:59 in this data based on daylight savings\n",
    "load_df['timestamp'] = load_df['timestamp'].dt.tz_localize('US/Pacific', ambiguous='infer', nonexistent='shift_forward') # Convert to Pacific and handle daylight savings time; continuous, so ambiguous = 'infer' should be OK\n",
    "print('Duplicate timestamps for load data:', load_df['timestamp'].duplicated().sum()) \n",
    "\n",
    "load_df.rename(columns={'CAISO': 'total_load'}, inplace=True) # Rename total load column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc977f70-7495-4e53-8495-d074b5868855",
   "metadata": {},
   "source": [
    "## Locational Marginal Price Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad1217-7a06-40ff-969c-a2b0cab1cff2",
   "metadata": {},
   "source": [
    "Total LMP data for 2023-2024 was pulled from the CAISO OASIS API in the 'LMP_data_query.ipynb' notebook. It is already UTC-formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00d78af-7deb-4426-94bb-015440aa740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import LMP data generated by other notebook\n",
    "lmp_df = pd.read_parquet('LMP/LMP_data.parquet').reset_index() # non-timestamp index easier for merging/operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8922cc",
   "metadata": {},
   "source": [
    "We will calculate a system-wide LMP using a load-weighted sum of the DLAP-specific LMPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bafcefdf-9c02-4c56-a46f-55f7a4a71953",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate system-wide DLAP load-weighted LMP using load and LMP data\n",
    "system_lmp_df = pd.DataFrame()\n",
    "system_lmp_df['total_lmp'] = (load_df['PGE'] * lmp_df['DLAP_PGAE-APND'] + load_df['SCE'] * lmp_df['DLAP_SCE-APND'] + load_df['SDGE'] * lmp_df['DLAP_SDGE-APND'] + load_df['VEA'] * lmp_df['DLAP_VEA-APND']) / load_df['total_load']\n",
    "system_lmp_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fed37d-de39-45a8-a8fb-a5c3f0a82319",
   "metadata": {},
   "source": [
    "## Battery Storage Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903f3e5-777c-4ffb-9212-96113e894186",
   "metadata": {},
   "source": [
    "We will use the battery charging delta (EN) and battery state of charge (SOC) data post pre-cleaning (described in the header)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9919f9f4-59a6-46a8-ac35-fc744c9670d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate timestamps for battery charging delta data: 0\n"
     ]
    }
   ],
   "source": [
    "## Import, format, and aggregate battery charging delta data\n",
    "battery_en_df = pd.read_csv(r'Battery/battery_en.csv')\n",
    "\n",
    "## Fix time alignment in battery storage data - spring forward is normal, but instead of duplicating an hour for fall back, hours count from 1 - 25\n",
    "## Fixing this manually by shifting the spring forward hours back before localizing and generating timestamps\n",
    "fall_back_2023 = '2023-11-05'\n",
    "fall_back_2024 = '2024-11-03'\n",
    "\n",
    "mask_2023 = battery_en_df['TRADE_DATE'] == fall_back_2023\n",
    "battery_en_df.loc[mask_2023 & (battery_en_df['HOUR'] >= 3), 'HOUR'] -= 1\n",
    "\n",
    "mask_2024 = battery_en_df['TRADE_DATE'] == fall_back_2024\n",
    "battery_en_df.loc[mask_2024 & (battery_en_df['HOUR'] >= 3), 'HOUR'] -= 1\n",
    "\n",
    "## Now create timestamp, localize, and convert to UTC\n",
    "battery_en_df['timestamp'] = pd.to_datetime(battery_en_df['TRADE_DATE']) + pd.to_timedelta(battery_en_df['HOUR'] - 1, unit='h') # Create timestamp column from 'TRADE_DATE' and 'HOUR'\n",
    "battery_en_df['timestamp'] = pd.to_datetime(battery_en_df['timestamp']).dt.tz_localize('US/Pacific', ambiguous='infer', nonexistent='shift_forward').dt.tz_convert('UTC') # Convert to Pacific and handle daylight savings time and then convert to UTC\n",
    "print('Duplicate timestamps for battery charging delta data:', battery_en_df['timestamp'].duplicated().sum()) # Check for duplicate timestamps after aligning to UTC\n",
    "\n",
    "## Rename columns\n",
    "battery_en_df.rename(columns={'VALUE': 'battery_en'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385998b7-ab57-4a96-94f9-45ba3a17c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import, format, and aggregate battery state-of-charge data\n",
    "battery_soc_df = pd.read_csv(r'Battery/battery_soc.csv')\n",
    "\n",
    "## Fix time alignment in battery storage data - spring forward is normal, but instead of duplicating an hour for fall back, hours count from 1 - 25\n",
    "## Fixing this manually by shifting the spring forward hours back before localizing and generating timestamps\n",
    "mask_2023 = battery_soc_df['TRADE_DATE'] == fall_back_2023\n",
    "battery_soc_df.loc[mask_2023 & (battery_soc_df['HOUR'] >= 3), 'HOUR'] -= 1\n",
    "\n",
    "mask_2024 = battery_soc_df['TRADE_DATE'] == fall_back_2024\n",
    "battery_soc_df.loc[mask_2024 & (battery_soc_df['HOUR'] >= 3), 'HOUR'] -= 1\n",
    "\n",
    "## Now create timestamp, localize, and convert to UTC\n",
    "battery_soc_df['timestamp'] = pd.to_datetime(battery_soc_df['TRADE_DATE']) + pd.to_timedelta(battery_soc_df['HOUR'] - 1, unit='h') # Create timestamp column from 'TRADE_DATE' and 'HOUR'\n",
    "battery_soc_df['timestamp'] = pd.to_datetime(battery_soc_df['timestamp']).dt.tz_localize('US/Pacific', ambiguous='infer', nonexistent='shift_forward').dt.tz_convert('UTC') # Convert to Pacific and handle daylight savings time and then convert to UTC\n",
    "\n",
    "## Rename columns\n",
    "battery_soc_df.rename(columns={'VALUE': 'battery_soc'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413bdeae-ad13-4964-a488-20db0ed7c279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours in time range of interest (2023-2024):  17544\n",
      "Length of production and curtailment data:  17544\n",
      "Length of load data:  17544\n",
      "Length of LMP data:  17544\n",
      "Length of battery charing delta data:  17497\n",
      "Length of battery state-of-charge data:  17497\n"
     ]
    }
   ],
   "source": [
    "## Check lengths of datasets\n",
    "print('Hours in time range of interest (2023-2024): ', 24*365*2+24) # 2024 was a leap year\n",
    "print('Length of production and curtailment data: ', len(prod_and_curt))\n",
    "print('Length of load data: ', len(load_df))\n",
    "print('Length of LMP data: ', len(lmp_df))\n",
    "print('Length of battery charing delta data: ', len(battery_en_df))\n",
    "print('Length of battery state-of-charge data: ', len(battery_soc_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04461fec",
   "metadata": {},
   "source": [
    "The battery datasets are not the same length as the other DataFrames, so they will need to be merged by timestamp. Otherwise, the data could become time-misaligned. The other datasets can be merged on index. We start by merging the production/curtailment, load, and LMP data by index. Then we merge the battery data by timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c47e232-b6b2-4d13-855d-75d661df95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create final DataFrame to merge all data sources together\n",
    "data_df = pd.DataFrame()\n",
    "data_df = pd.merge(prod_and_curt, load_df[['total_load']], left_index=True, right_index=True, how='outer') # Merge production, curtailment, imports/exports, and load\n",
    "data_df = pd.merge(data_df, system_lmp_df[['total_lmp']], left_index=True, right_index=True, how='outer') # Merge in LMP and congestion LMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d05cd3a-ab86-4c92-a8a0-9ce224788853",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge in battery storage by timestamps because 47 hours are missing\n",
    "data_df = pd.merge(data_df, battery_en_df[['timestamp', 'battery_en']], on='timestamp', how='left') # Merge left to ensure all hours are kept\n",
    "data_df = pd.merge(data_df, battery_soc_df[['timestamp', 'battery_soc']], on='timestamp', how='left') # Merge left to ensure all hours are kept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99975b0c",
   "metadata": {},
   "source": [
    "We next extract the month from our timestamp to convert into dummy season variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1743b08d-cd47-41ca-bd51-ee71caba7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set timestamp as index and add columns for hour and month\n",
    "data_df.set_index('timestamp', inplace=True)\n",
    "data_df['month'] = data_df.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08aee144-3365-4928-ae9c-fd74ffd0fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert months into categories (season) for broader temporal patterns\n",
    "season_mapping = {12: 'winter', 1: 'winter', 2: 'winter',\n",
    "                  3: 'spring', 4: 'spring', 5: 'spring',\n",
    "                  6: 'summer', 7: 'summer', 8: 'summer',\n",
    "                  9: 'fall', 10: 'fall', 11: 'fall'}\n",
    "\n",
    "data_df['season'] = data_df['month'].map(season_mapping)\n",
    "\n",
    "# Dummy variables for seasons\n",
    "data_df = pd.get_dummies(data_df, columns=['season'], drop_first=True)\n",
    "\n",
    "# Convert to integers\n",
    "dummy_cols = ['season_summer', 'season_winter', 'season_spring']\n",
    "data_df[dummy_cols] = data_df[dummy_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53f8e0ac-5fe1-43c9-9b7b-a36cb1cc572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data values by column: \n",
      "percent_wind_gen      0\n",
      "percent_solar_gen     0\n",
      "total_curtailment     0\n",
      "exports               0\n",
      "total_load            0\n",
      "total_lmp             0\n",
      "battery_en           47\n",
      "battery_soc          47\n",
      "month                 0\n",
      "season_spring         0\n",
      "season_summer         0\n",
      "season_winter         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Check for missing values\n",
    "print('Missing data values by column: ')\n",
    "print(data_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619fb113",
   "metadata": {},
   "source": [
    "As we saw before, both battery features are missing 47 hours of data. We will determine the importance of this missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682414d-2628-4c3d-b0b9-9ef81e035d94",
   "metadata": {},
   "source": [
    "## Missing Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a957b0-39c2-485b-9377-5831b33ca119",
   "metadata": {},
   "source": [
    "Check whether 47 missing hours of battery storage data are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "467505a9-f424-4cee-aef5-81fa719d9171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.268% of hours missing battery storage information.\n"
     ]
    }
   ],
   "source": [
    "## Identify how much data is missing\n",
    "missing_data = data_df[data_df['battery_en'].isnull() | data_df['battery_soc'].isnull()]\n",
    "print(f'{round((len(missing_data)/len(data_df))*100, 3)}% of hours missing battery storage information.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479193f",
   "metadata": {},
   "source": [
    "This is a tiny fraction of our overall data, so we can fill it in linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23715819-9969-4a8d-af26-a5bf11a67e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in missing battery data linearly\n",
    "data_df['battery_soc'] = data_df['battery_soc'].interpolate(method='linear')\n",
    "\n",
    "# Use changes in storage data to fill in missing charge/discharge data\n",
    "data_df['storage_delta'] = data_df['battery_soc'].diff() # Capture changes in battery storage\n",
    "data_df['battery_en'] = data_df['battery_en'].fillna(data_df['storage_delta']) # Fill missing values in charging/discharging data\n",
    "data_df = data_df.drop(columns='storage_delta') # Drop storage delta data from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe559fbf-b973-4ced-90c7-1c925e8c8da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data values by column: \n",
      "percent_wind_gen     0\n",
      "percent_solar_gen    0\n",
      "total_curtailment    0\n",
      "exports              0\n",
      "total_load           0\n",
      "total_lmp            0\n",
      "battery_en           0\n",
      "battery_soc          0\n",
      "month                0\n",
      "season_spring        0\n",
      "season_summer        0\n",
      "season_winter        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Validate that there are no more missing values\n",
    "print('Missing data values by column: ')\n",
    "print(data_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da752e4",
   "metadata": {},
   "source": [
    "Now, we can reorganize our columns and drop our timestamp. Finally, we can save our data to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b094cdac-e364-42c9-8173-36d586f42aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reorder columns to have response variable at end and drop timestamp (not actually a feature)\n",
    "data_df = data_df[['percent_wind_gen', 'percent_solar_gen', 'exports', 'total_load', 'total_lmp', 'battery_en', 'battery_soc', 'season_summer', 'season_spring', 'season_winter', 'total_curtailment']]\n",
    "data_df.reset_index(inplace=True)\n",
    "data_df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a03e14a-c3a3-4990-81d6-005b85389196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_wind_gen</th>\n",
       "      <th>percent_solar_gen</th>\n",
       "      <th>exports</th>\n",
       "      <th>total_load</th>\n",
       "      <th>total_lmp</th>\n",
       "      <th>battery_en</th>\n",
       "      <th>battery_soc</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_spring</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>total_curtailment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.265874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-69960.360000</td>\n",
       "      <td>21302.162944</td>\n",
       "      <td>114.687870</td>\n",
       "      <td>41.976</td>\n",
       "      <td>6524.477167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-67462.573333</td>\n",
       "      <td>20803.750237</td>\n",
       "      <td>108.752210</td>\n",
       "      <td>-5.863</td>\n",
       "      <td>6460.896417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-65642.693333</td>\n",
       "      <td>20300.078086</td>\n",
       "      <td>102.776174</td>\n",
       "      <td>-54.224</td>\n",
       "      <td>6465.033667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-64974.106667</td>\n",
       "      <td>19914.921017</td>\n",
       "      <td>106.676475</td>\n",
       "      <td>19.609</td>\n",
       "      <td>6460.216500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.292937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-65427.986667</td>\n",
       "      <td>19975.842246</td>\n",
       "      <td>110.358796</td>\n",
       "      <td>8.992</td>\n",
       "      <td>6428.138083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.279927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-61790.453333</td>\n",
       "      <td>20273.688572</td>\n",
       "      <td>112.348333</td>\n",
       "      <td>581.266</td>\n",
       "      <td>6564.830417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.274556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-61654.080000</td>\n",
       "      <td>20534.584181</td>\n",
       "      <td>113.756832</td>\n",
       "      <td>1112.432</td>\n",
       "      <td>6379.488417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.254857</td>\n",
       "      <td>0.034031</td>\n",
       "      <td>-51741.000000</td>\n",
       "      <td>20510.883304</td>\n",
       "      <td>103.788766</td>\n",
       "      <td>1043.191</td>\n",
       "      <td>5441.492833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.240082</td>\n",
       "      <td>0.216341</td>\n",
       "      <td>-38545.640000</td>\n",
       "      <td>20179.969086</td>\n",
       "      <td>112.740669</td>\n",
       "      <td>6.937</td>\n",
       "      <td>5108.654417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.224064</td>\n",
       "      <td>0.324019</td>\n",
       "      <td>-20055.786667</td>\n",
       "      <td>19656.011666</td>\n",
       "      <td>103.003784</td>\n",
       "      <td>-791.843</td>\n",
       "      <td>5420.171250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percent_wind_gen  percent_solar_gen       exports    total_load  \\\n",
       "0          0.265874           0.000000 -69960.360000  21302.162944   \n",
       "1          0.303146           0.000000 -67462.573333  20803.750237   \n",
       "2          0.327688           0.000000 -65642.693333  20300.078086   \n",
       "3          0.326433           0.000000 -64974.106667  19914.921017   \n",
       "4          0.292937           0.000000 -65427.986667  19975.842246   \n",
       "5          0.279927           0.000000 -61790.453333  20273.688572   \n",
       "6          0.274556           0.000000 -61654.080000  20534.584181   \n",
       "7          0.254857           0.034031 -51741.000000  20510.883304   \n",
       "8          0.240082           0.216341 -38545.640000  20179.969086   \n",
       "9          0.224064           0.324019 -20055.786667  19656.011666   \n",
       "\n",
       "    total_lmp  battery_en  battery_soc  season_summer  season_spring  \\\n",
       "0  114.687870      41.976  6524.477167              0              0   \n",
       "1  108.752210      -5.863  6460.896417              0              0   \n",
       "2  102.776174     -54.224  6465.033667              0              0   \n",
       "3  106.676475      19.609  6460.216500              0              0   \n",
       "4  110.358796       8.992  6428.138083              0              0   \n",
       "5  112.348333     581.266  6564.830417              0              0   \n",
       "6  113.756832    1112.432  6379.488417              0              0   \n",
       "7  103.788766    1043.191  5441.492833              0              0   \n",
       "8  112.740669       6.937  5108.654417              0              0   \n",
       "9  103.003784    -791.843  5420.171250              0              0   \n",
       "\n",
       "   season_winter  total_curtailment  \n",
       "0              1              0.000  \n",
       "1              1              0.000  \n",
       "2              1              0.000  \n",
       "3              1              0.000  \n",
       "4              1              0.000  \n",
       "5              1              0.000  \n",
       "6              1              0.000  \n",
       "7              1              0.000  \n",
       "8              1              0.000  \n",
       "9              1              2.925  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preview the data\n",
    "data_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac3e980e-1749-4c1f-953c-c0df98de24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data as CSV\n",
    "data_df.to_csv('cleaned_data.csv', index=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
